{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import ntpath\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "\n",
    "out_file = open('segmented_ALL_texts.txt', 'w')\n",
    "\n",
    "file_count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(\"whole_data\"):\n",
    "    print (root)\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):       \n",
    "            filename = ntpath.basename(file)\n",
    "            with open ((os.path.join(root, file)), \"r\") as infile:\n",
    "                print (\"Opening file: \", (os.path.join(root, file)))\n",
    "                document = infile.readlines()\n",
    "                file_count+=1\n",
    "                #print (document)\n",
    "                for paragraph in document:\n",
    "                    sent_tokenized_list = sent_tokenize(paragraph)\n",
    "                    out_file.write(\"\\n\".join(sent_tokenized_list) )\n",
    "out_file.close()\n",
    "            \n",
    "print (file_count)                    \n",
    "#after, in terminal: cat segmented_ALL_texts.txt| sed -n '/journal\\.pone/!p' > cleaned_segmented_whole.txt  (get read of 'help lines referring to tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "import logging\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import *\n",
    "\n",
    "documents = TaggedLineDocument(\"cleaned_segmented_whole.txt\")\n",
    "model = Doc2Vec(documents, vector_size=100, window=8, min_count=1, workers=4)\n",
    "model.save(\"plosone_doc2vec.vec\")       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qt402/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('prostate', 0.6743712425231934),\n",
       " ('cancer.', 0.6500186324119568),\n",
       " ('cancer,', 0.620056688785553),\n",
       " ('quality-specific', 0.61820387840271),\n",
       " ('endometrial', 0.6146716475486755),\n",
       " ('118).', 0.6074773073196411),\n",
       " ('cancers', 0.5930484533309937),\n",
       " ('colorectal', 0.5908399820327759),\n",
       " ('Jade', 0.5904192328453064),\n",
       " ('melanoma', 0.5845313668251038)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['breast','cancer'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
